{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fname = 'voyna-i-mir-tom-1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "def loss_plot(fig, ax, train_loss, test_loss, loss_name):\n",
    "    train_line = ax.plot(train_loss, color = 'black')\n",
    "    test_line = ax.plot(test_loss, color = 'red')\n",
    "    ax.set_xlabel('Эпоха')\n",
    "    ax.set_ylabel(loss_name)\n",
    "    ax.legend(('Тренировочная выборка', 'Тестовая выборка'))\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_CHAR = '\\b'\n",
    "END_CHAR = '\\t'\n",
    "PADDING_CHAR = '\\a'\n",
    "chars = set([START_CHAR, '\\n', END_CHAR])\n",
    "with open(input_fname) as f:\n",
    "    for line in f:\n",
    "        chars.update(list(line.strip().lower()))\n",
    "char_indices = {c: i + 1 for i,c in enumerate(sorted(list(chars)))}\n",
    "char_indices[PADDING_CHAR] = 0\n",
    "indices_to_chars = {i: c for c, i in char_indices.items()}\n",
    "num_chars = len(chars) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one(i , sz):\n",
    "    res = np.zeros(sz)\n",
    "    res[i] = 1\n",
    "    return res\n",
    "\n",
    "char_vectors = {\n",
    "    c : (np.zeros(num_chars) if c == PADDING_CHAR else get_one(v, num_chars))\n",
    "    for c, v in char_indices.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#т.к. анализую войну и мир, немного своя предобработка текста\n",
    "sentences = []\n",
    "text = ''\n",
    "with open(input_fname, 'r') as f:\n",
    "    for line in f:\n",
    "        s = re.split('[.!?\\-\\]\\[]', line.strip().lower())\n",
    "        for sentence in s:\n",
    "            if len(sentence) > 30:\n",
    "                sentences.append(sentence.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrices(sentences):\n",
    "    max_sentence_len = np.max([len(x) for x in sentences])\n",
    "    X = np.zeros((len(sentences), max_sentence_len, num_chars), dtype = np.bool)\n",
    "    y = np.zeros((len(sentences), max_sentence_len), dtype = np.long)\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        char_seq = (START_CHAR + sentence + END_CHAR).ljust(max_sentence_len + 1, PADDING_CHAR)\n",
    "        for t in range(max_sentence_len):\n",
    "            X[i, t, :] = char_vectors[char_seq[t]]\n",
    "            #индекс символа, т.к. в торче своеобразный лосс\n",
    "            y[i, t] = np.argmax(char_vectors[char_seq[t + 1]])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = np.random.choice(range(len(sentences)), int(len(sentences) * 0.05))\n",
    "sentences_train = [sentences[x] for x in set(range(len(sentences))) - set(test_indices)]\n",
    "sentences_test = [sentences[x] for x in test_indices]\n",
    "sentences_train = sorted(sentences_train, key = lambda x: len(x))\n",
    "X_test, y_test = get_matrices(sentences_test)\n",
    "X_test = torch.from_numpy(X_test).to(device).float()\n",
    "y_test = torch.from_numpy(y_test).to(device).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "def generate_batch():\n",
    "    while True:\n",
    "        for i in range(int(len(sentences) / batch_size)):\n",
    "            sentences_batch = sentences_train[i * batch_size : (i+1) * batch_size]\n",
    "            if (len(sentences_batch)  == 0): break\n",
    "            yield get_matrices(sentences_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReqModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(num_chars, 128, batch_first = True)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        self.dense = nn.Linear(128, num_chars)\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X, _ = self.lstm(X)\n",
    "        X = self.tanh(X)\n",
    "        X = torch.reshape(X, (-1, 128))\n",
    "        X = self.drop(X)\n",
    "        X = self.dense(X)\n",
    "        #X = self.softmax(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ReqModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "cross_entropy = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Провожу эксперимент по обучению без обрезки градиентов\n",
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "ax = fig.subplots(2,1)\n",
    "fig.tight_layout(pad=3.0)\n",
    "ax1, ax2 = ax\n",
    "\n",
    "epochs = 101\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "test_loss_no_clip = []\n",
    "test_acc_no_clip = []\n",
    "for e in range(epochs):\n",
    "    train_loss_epoch = 0\n",
    "    train_acc_epoch = 0\n",
    "    generator = generate_batch()\n",
    "    for i in range(int(len(sentences) / batch_size)):\n",
    "        X, y = next(generator)\n",
    "        X = torch.from_numpy(X).to(device).float()\n",
    "        y = torch.from_numpy(y).to(device).long()\n",
    "        logits = model(X)\n",
    "        loss = cross_entropy(logits, y.reshape(-1))\n",
    "        train_loss_epoch += loss.item()\n",
    "        train_acc_epoch += torch.mean((y.reshape(-1) == torch.argmax(logits, -1)).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    train_loss_epoch /= int(len(sentences) / batch_size)\n",
    "    train_acc_epoch /= int(len(sentences) / batch_size)\n",
    "    train_loss.append(train_loss_epoch)\n",
    "    train_acc.append(train_acc_epoch)\n",
    "    print(f'Эпоха {e}')\n",
    "    print(f'Тренировочный лосс: {train_loss[-1]}  точность:{train_acc[-1]}')\n",
    "    with torch.no_grad():\n",
    "        logits_test = model(X_test)\n",
    "        loss = cross_entropy(logits_test, y_test.reshape(-1))\n",
    "        test_loss_no_clip.append(loss.item())\n",
    "        test_acc_no_clip.append(torch.mean((y_test.reshape(-1) == torch.argmax(logits_test, -1)).float()))\n",
    "    print(f'Тестовый лосс: {test_loss[-1]}  точность:{test_acc[-1]}')\n",
    "    loss_plot(fig,ax1,train_loss, test_loss_no_clip, \"Кросс-энтропия\")\n",
    "    loss_plot(fig,ax2,train_acc, test_acc_no_clip, \"Точность\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "class CharSampler():\n",
    "    def __init__(self, char_vectors, model, filename):\n",
    "        self.char_vectors = char_vectors\n",
    "        self.model = model\n",
    "        if os.path.exists(filename):\n",
    "            os.remove(filename)\n",
    "        self.filename = filename\n",
    "        \n",
    "    def sample(self, preds, temperature):\n",
    "        #тут функция немного изменилась по сранению с книгой, надеюсь, не ошибся\n",
    "        preds = preds.cpu().numpy().astype('float64')\n",
    "        preds = preds / temperature\n",
    "        exp_preds = np.exp(preds) \n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        probas = np.random.multinomial(1, preds.reshape(-1), 1)\n",
    "        #probas = preds\n",
    "        \n",
    "        return np.argmax(probas)\n",
    "    \n",
    "    def sample_one(self, T):\n",
    "        with torch.no_grad():\n",
    "            result = START_CHAR\n",
    "            while len(result) < 300:\n",
    "                X_sampled = np.zeros((1, len(result), num_chars))\n",
    "                for t, c in enumerate(list(result)):\n",
    "                    X_sampled[0,t, :] = self.char_vectors[c]\n",
    "                X_sampled = torch.from_numpy(X_sampled).to(device).float()\n",
    "                y_sampled = self.model(X_sampled)\n",
    "                yv = y_sampled[len(result)-1:]\n",
    "                selected_char = indices_to_chars[self.sample(yv, T)]\n",
    "                if selected_char==END_CHAR:\n",
    "                    break\n",
    "                result = result + selected_char\n",
    "            return result\n",
    "    \n",
    "    def on_epoch_end(self, epoch):\n",
    "        if epoch % 20 == 0:\n",
    "            print(\"Started sampling\")\n",
    "            with open(self.filename, 'a', encoding=\"utf-8\") as outf:\n",
    "                outf.write(f'\\nЭпоха {epoch}\\n')\n",
    "                for T in [0.3, 0.5, 0.7, 0.9, 1.1]:\n",
    "                    print(f'\\tsampling, T = {T: .1f}')\n",
    "                    for _ in range(5):\n",
    "                        res = self.sample_one(T)\n",
    "                        outf.write(f'\\nT = {T: .1f}\\n {res[1:]}\\n')\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: notebook. Using widget instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfde83d332f241a59124a5f6bd638b99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 0\n",
      "Тренировочный лосс: 3.1866448262158564  точность:0.16681286692619324\n",
      "Тестовый лосс: 4.2296624183654785  точность:0.04495524242520332\n",
      "Started sampling\n",
      "\tsampling, T =  0.3\n",
      "\tsampling, T =  0.5\n",
      "\tsampling, T =  0.7\n",
      "\tsampling, T =  0.9\n",
      "\tsampling, T =  1.1\n",
      "Эпоха 1\n",
      "Тренировочный лосс: 2.6507953290378348  точность:0.24295692145824432\n",
      "Тестовый лосс: 4.434423923492432  точность:0.04969309642910957\n",
      "Эпоха 2\n",
      "Тренировочный лосс: 2.492383592829985  точность:0.27468207478523254\n",
      "Тестовый лосс: 4.011533737182617  точность:0.05593350529670715\n",
      "Эпоха 3\n",
      "Тренировочный лосс: 2.3974051037956685  точность:0.29907044768333435\n",
      "Тестовый лосс: 2.977808952331543  точность:0.05969948694109917\n",
      "Эпоха 4\n",
      "Тренировочный лосс: 2.3226902731727153  точность:0.31694796681404114\n",
      "Тестовый лосс: 2.1637611389160156  точность:0.6357736587524414\n",
      "Эпоха 5\n",
      "Тренировочный лосс: 2.2544123879600972  точность:0.33509117364883423\n",
      "Тестовый лосс: 0.7658377885818481  точность:0.859098494052887\n",
      "Эпоха 6\n",
      "Тренировочный лосс: 2.1936955359402823  точность:0.3507591784000397\n",
      "Тестовый лосс: 0.5498195290565491  точность:0.8647953867912292\n",
      "Эпоха 7\n",
      "Тренировочный лосс: 2.1416016208424287  точность:0.36488646268844604\n",
      "Тестовый лосс: 0.4816700518131256  точность:0.8684654831886292\n",
      "Эпоха 8\n",
      "Тренировочный лосс: 2.095334867028629  точность:0.3778996467590332\n",
      "Тестовый лосс: 0.4554693400859833  точность:0.8722761869430542\n",
      "Эпоха 9\n",
      "Тренировочный лосс: 2.05246214614195  точность:0.3900032937526703\n",
      "Тестовый лосс: 0.43968865275382996  точность:0.8745396137237549\n",
      "Эпоха 10\n",
      "Тренировочный лосс: 2.014396108739516  точность:0.40124163031578064\n",
      "Тестовый лосс: 0.4272415339946747  точность:0.8772059082984924\n",
      "Эпоха 11\n",
      "Тренировочный лосс: 1.9797685121087467  точность:0.4116029441356659\n",
      "Тестовый лосс: 0.4207439720630646  точность:0.8780818581581116\n",
      "Эпоха 12\n",
      "Тренировочный лосс: 1.9501288831935208  точность:0.41948434710502625\n",
      "Тестовый лосс: 0.4126437306404114  точность:0.8794437050819397\n",
      "Эпоха 13\n",
      "Тренировочный лосс: 1.9229954854179832  точность:0.4267699420452118\n",
      "Тестовый лосс: 0.4073512554168701  точность:0.8812020421028137\n",
      "Эпоха 14\n",
      "Тренировочный лосс: 1.8994585878708783  точность:0.43393203616142273\n",
      "Тестовый лосс: 0.40323883295059204  точность:0.8818350434303284\n",
      "Эпоха 15\n",
      "Тренировочный лосс: 1.8774531033459831  точность:0.43958404660224915\n",
      "Тестовый лосс: 0.4808066785335541  точность:0.8824936151504517\n",
      "Эпоха 16\n",
      "Тренировочный лосс: 1.8582513021020328  точность:0.4449930489063263\n",
      "Тестовый лосс: 0.3966953754425049  точность:0.8844053745269775\n",
      "Эпоха 17\n",
      "Тренировочный лосс: 1.839186541332918  точность:0.45023733377456665\n",
      "Тестовый лосс: 0.3938893973827362  точность:0.8845971822738647\n",
      "Эпоха 18\n",
      "Тренировочный лосс: 1.821398749071009  точность:0.4540818929672241\n",
      "Тестовый лосс: 0.3923000395298004  точность:0.8850255608558655\n",
      "Эпоха 19\n",
      "Тренировочный лосс: 1.806893767749562  точность:0.4585992395877838\n",
      "Тестовый лосс: 0.3897630274295807  точность:0.8852813243865967\n",
      "Эпоха 20\n",
      "Тренировочный лосс: 1.7918643006156472  точность:0.4630338251590729\n",
      "Тестовый лосс: 0.3862244486808777  точность:0.8862979412078857\n",
      "Started sampling\n",
      "\tsampling, T =  0.3\n",
      "\tsampling, T =  0.5\n",
      "\tsampling, T =  0.7\n",
      "\tsampling, T =  0.9\n",
      "\tsampling, T =  1.1\n",
      "Эпоха 21\n",
      "Тренировочный лосс: 1.7782345861547133  точность:0.46588587760925293\n",
      "Тестовый лосс: 0.3856123089790344  точность:0.8860613703727722\n",
      "Эпоха 22\n",
      "Тренировочный лосс: 1.7645459138645845  точность:0.4700755476951599\n",
      "Тестовый лосс: 0.38441359996795654  точность:0.887084424495697\n",
      "Эпоха 23\n",
      "Тренировочный лосс: 1.7524902430702658  точность:0.47311779856681824\n",
      "Тестовый лосс: 0.3819306492805481  точность:0.8867838978767395\n",
      "Эпоха 24\n",
      "Тренировочный лосс: 1.7414197094300214  точность:0.47700244188308716\n",
      "Тестовый лосс: 0.37976276874542236  точность:0.8879348039627075\n",
      "Эпоха 25\n",
      "Тренировочный лосс: 1.7318788907107185  точность:0.47906553745269775\n",
      "Тестовый лосс: 0.4258950352668762  точность:0.882953941822052\n",
      "Эпоха 26\n",
      "Тренировочный лосс: 1.72221803076127  точность:0.482072651386261\n",
      "Тестовый лосс: 7.724740028381348  точность:0.1414833813905716\n",
      "Эпоха 27\n",
      "Тренировочный лосс: 1.7133194987914142  точность:0.48428332805633545\n",
      "Тестовый лосс: 0.4052800238132477  точность:0.8870076537132263\n",
      "Эпоха 28\n",
      "Тренировочный лосс: 1.7041038137323716  точность:0.4870443344116211\n",
      "Тестовый лосс: 0.744408130645752  точность:0.8142455220222473\n",
      "Эпоха 29\n",
      "Тренировочный лосс: 1.6955045910442577  точность:0.48904094099998474\n",
      "Тестовый лосс: 0.37627866864204407  точность:0.8890409469604492\n",
      "Эпоха 30\n",
      "Тренировочный лосс: 1.687713381542879  точность:0.49072593450546265\n",
      "Тестовый лосс: 0.3774576783180237  точность:0.8884654641151428\n",
      "Эпоха 31\n",
      "Тренировочный лосс: 1.6803581254622515  точность:0.49381381273269653\n",
      "Тестовый лосс: 0.3763123154640198  точность:0.8894820809364319\n",
      "Эпоха 32\n",
      "Тренировочный лосс: 1.67328653531916  точность:0.49550193548202515\n",
      "Тестовый лосс: 0.3769090175628662  точность:0.889398992061615\n",
      "Эпоха 33\n",
      "Тренировочный лосс: 1.665780673307531  точность:0.49737653136253357\n",
      "Тестовый лосс: 0.4343353807926178  точность:0.8795204758644104\n",
      "Эпоха 34\n",
      "Тренировочный лосс: 1.65991247289321  точность:0.49799230694770813\n",
      "Тестовый лосс: 0.3769168257713318  точность:0.8891176581382751\n",
      "Эпоха 35\n",
      "Тренировочный лосс: 1.6549040567173678  точность:0.49999022483825684\n",
      "Тестовый лосс: 0.37541794776916504  точность:0.888785183429718\n",
      "Эпоха 36\n",
      "Тренировочный лосс: 1.6485990555146162  точность:0.5020272135734558\n",
      "Тестовый лосс: 0.37491515278816223  точность:0.8892583250999451\n",
      "Эпоха 37\n",
      "Тренировочный лосс: 1.6427222947513356  точность:0.5030249357223511\n",
      "Тестовый лосс: 0.37862566113471985  точность:0.8885805606842041\n",
      "Эпоха 38\n",
      "Тренировочный лосс: 1.637157021410325  точность:0.5048054456710815\n",
      "Тестовый лосс: 1.0402781963348389  точность:0.780971884727478\n",
      "Эпоха 39\n",
      "Тренировочный лосс: 1.6336513163061703  точность:0.5049938559532166\n",
      "Тестовый лосс: 0.3900426924228668  точность:0.889335036277771\n",
      "Эпоха 40\n",
      "Тренировочный лосс: 1.6273592169144575  точность:0.5075331330299377\n",
      "Тестовый лосс: 0.37498652935028076  точность:0.8898529410362244\n",
      "Started sampling\n",
      "\tsampling, T =  0.3\n",
      "\tsampling, T =  0.5\n",
      "\tsampling, T =  0.7\n",
      "\tsampling, T =  0.9\n",
      "\tsampling, T =  1.1\n",
      "Эпоха 41\n",
      "Тренировочный лосс: 1.6237933860105627  точность:0.508510410785675\n",
      "Тестовый лосс: 0.38155481219291687  точность:0.8887467980384827\n",
      "Эпоха 42\n",
      "Тренировочный лосс: 1.6186211989907657  точность:0.5095282793045044\n",
      "Тестовый лосс: 0.3941881060600281  точность:0.8887723684310913\n",
      "Эпоха 43\n",
      "Тренировочный лосс: 1.6147941704357371  точность:0.5107348561286926\n",
      "Тестовый лосс: 0.3847814202308655  точность:0.8884782791137695\n",
      "Эпоха 44\n",
      "Тренировочный лосс: 1.6091241090437944  точность:0.5123965740203857\n",
      "Тестовый лосс: 0.40483027696609497  точность:0.8869885206222534\n",
      "Эпоха 45\n",
      "Тренировочный лосс: 1.605816778014688  точность:0.5131170749664307\n",
      "Тестовый лосс: 0.38856521248817444  точность:0.8895076513290405\n",
      "Эпоха 46\n",
      "Тренировочный лосс: 1.6023245421577903  точность:0.5141099095344543\n",
      "Тестовый лосс: 0.49301081895828247  точность:0.8649104833602905\n",
      "Эпоха 47\n",
      "Тренировочный лосс: 1.5970951293496525  точность:0.516562819480896\n",
      "Тестовый лосс: 0.37726330757141113  точность:0.8892838954925537\n",
      "Эпоха 48\n",
      "Тренировочный лосс: 1.5944034161287195  точность:0.5164317488670349\n",
      "Тестовый лосс: 0.3966311812400818  точность:0.8877238035202026\n",
      "Эпоха 49\n",
      "Тренировочный лосс: 1.5925137410444372  точность:0.5167884826660156\n",
      "Тестовый лосс: 0.38004758954048157  точность:0.8884718418121338\n",
      "Эпоха 50\n",
      "Тренировочный лосс: 1.5870889498205747  точность:0.518225371837616\n",
      "Тестовый лосс: 0.4161572754383087  точность:0.885869562625885\n",
      "Эпоха 51\n",
      "Тренировочный лосс: 1.5839985494052662  точность:0.5196016430854797\n",
      "Тестовый лосс: 0.39562875032424927  точность:0.888190507888794\n",
      "Эпоха 52\n",
      "Тренировочный лосс: 1.58162615888259  точность:0.5196053385734558\n",
      "Тестовый лосс: 0.4192814528942108  точность:0.8858503699302673\n",
      "Эпоха 53\n",
      "Тренировочный лосс: 1.5774309820287369  точность:0.5216380953788757\n",
      "Тестовый лосс: 0.3827923834323883  точность:0.888184130191803\n",
      "Эпоха 54\n",
      "Тренировочный лосс: 1.5753889229718376  точность:0.5216200947761536\n",
      "Тестовый лосс: 0.42478644847869873  точность:0.8853452801704407\n",
      "Эпоха 55\n",
      "Тренировочный лосс: 1.5730599195816937  точность:0.5218605399131775\n",
      "Тестовый лосс: 5.959614276885986  точность:0.45586317777633667\n",
      "Эпоха 56\n",
      "Тренировочный лосс: 1.5704319406958187  точность:0.5235139727592468\n",
      "Тестовый лосс: 0.38483479619026184  точность:0.8888747096061707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 57\n",
      "Тренировочный лосс: 1.5675070681291468  точность:0.5240395069122314\n",
      "Тестовый лосс: 0.3800201714038849  точность:0.889264702796936\n",
      "Эпоха 58\n",
      "Тренировочный лосс: 1.5639466813031364  точность:0.5255091190338135\n",
      "Тестовый лосс: 0.38558775186538696  точность:0.8889961838722229\n",
      "Эпоха 59\n",
      "Тренировочный лосс: 1.5631523157568539  точность:0.5248302221298218\n",
      "Тестовый лосс: 0.38102731108665466  точность:0.8888107538223267\n",
      "Эпоха 60\n",
      "Тренировочный лосс: 1.5592730642767514  точность:0.5262420177459717\n",
      "Тестовый лосс: 0.3883562386035919  точность:0.8890025615692139\n",
      "Started sampling\n",
      "\tsampling, T =  0.3\n",
      "\tsampling, T =  0.5\n",
      "\tsampling, T =  0.7\n",
      "\tsampling, T =  0.9\n",
      "\tsampling, T =  1.1\n",
      "Эпоха 61\n",
      "Тренировочный лосс: 1.5578877247081084  точность:0.5261783003807068\n",
      "Тестовый лосс: 0.3815257251262665  точность:0.889271080493927\n",
      "Эпоха 62\n",
      "Тренировочный лосс: 1.5546986150741577  точность:0.5277594327926636\n",
      "Тестовый лосс: 0.39694318175315857  точность:0.8878836035728455\n",
      "Эпоха 63\n",
      "Тренировочный лосс: 1.5531584139431225  точность:0.5284762978553772\n",
      "Тестовый лосс: 0.39344075322151184  точность:0.8878772258758545\n",
      "Эпоха 64\n",
      "Тренировочный лосс: 1.551163766524371  точность:0.5284469723701477\n",
      "Тестовый лосс: 0.3980034291744232  точность:0.8873337507247925\n",
      "Эпоха 65\n",
      "Тренировочный лосс: 1.5482472795598647  точность:0.5291476845741272\n",
      "Тестовый лосс: 0.4324895143508911  точность:0.8848848938941956\n",
      "Эпоха 66\n",
      "Тренировочный лосс: 1.5463753523546107  точность:0.5298432111740112\n",
      "Тестовый лосс: 0.410221666097641  точность:0.886489748954773\n",
      "Эпоха 67\n",
      "Тренировочный лосс: 1.543788314707139  точность:0.5305203795433044\n",
      "Тестовый лосс: 0.42089933156967163  точность:0.8858823776245117\n",
      "Эпоха 68\n",
      "Тренировочный лосс: 1.5424493099661434  точность:0.5307021141052246\n",
      "Тестовый лосс: 0.3910380005836487  точность:0.8880562782287598\n",
      "Эпоха 69\n",
      "Тренировочный лосс: 1.5407492177626665  точность:0.5313198566436768\n",
      "Тестовый лосс: 0.4092520773410797  точность:0.8866879940032959\n",
      "Эпоха 70\n",
      "Тренировочный лосс: 1.537105117966147  точность:0.5319880247116089\n",
      "Тестовый лосс: 0.3906157314777374  точность:0.8876726627349854\n",
      "Эпоха 71\n",
      "Тренировочный лосс: 1.5376855900708366  точность:0.5322532653808594\n",
      "Тестовый лосс: 0.43497031927108765  точность:0.8837851881980896\n",
      "Эпоха 72\n",
      "Тренировочный лосс: 1.5358872893277336  точность:0.5324714183807373\n",
      "Тестовый лосс: 0.4397353529930115  точность:0.8852685689926147\n",
      "Эпоха 73\n",
      "Тренировочный лосс: 1.5333983575596528  точность:0.5333710312843323\n",
      "Тестовый лосс: 1.5954371690750122  точность:0.7531905174255371\n",
      "Эпоха 74\n",
      "Тренировочный лосс: 1.5345479418249692  точность:0.5328484773635864\n",
      "Тестовый лосс: 1.363834023475647  точность:0.7978772521018982\n",
      "Эпоха 75\n",
      "Тренировочный лосс: 1.5318932732413797  точность:0.5340455174446106\n",
      "Тестовый лосс: 4.461940288543701  точность:0.5473912954330444\n",
      "Эпоха 76\n",
      "Тренировочный лосс: 1.529356642891379  точность:0.5343707203865051\n",
      "Тестовый лосс: 0.3988862931728363  точность:0.887033224105835\n",
      "Эпоха 77\n",
      "Тренировочный лосс: 1.5275798806022196  точность:0.534741997718811\n",
      "Тестовый лосс: 0.4342435300350189  точность:0.8851342797279358\n",
      "Эпоха 78\n",
      "Тренировочный лосс: 1.5258727328917558  точность:0.5353491306304932\n",
      "Тестовый лосс: 0.4280485212802887  точность:0.8835933804512024\n",
      "Эпоха 79\n",
      "Тренировочный лосс: 1.5237611540626077  точность:0.536263644695282\n",
      "Тестовый лосс: 0.4239148795604706  точность:0.8848657011985779\n",
      "Эпоха 80\n",
      "Тренировочный лосс: 1.5226812567430383  точность:0.5365846157073975\n",
      "Тестовый лосс: 0.41146788001060486  точность:0.8854219913482666\n",
      "Started sampling\n",
      "\tsampling, T =  0.3\n",
      "\tsampling, T =  0.5\n",
      "\tsampling, T =  0.7\n",
      "\tsampling, T =  0.9\n",
      "\tsampling, T =  1.1\n",
      "Эпоха 81\n",
      "Тренировочный лосс: 1.5219743922177482  точность:0.53677898645401\n",
      "Тестовый лосс: 0.39457249641418457  точность:0.8873657584190369\n",
      "Эпоха 82\n",
      "Тренировочный лосс: 1.520584083444932  точность:0.5374022722244263\n",
      "Тестовый лосс: 0.4396893084049225  точность:0.8833311796188354\n",
      "Эпоха 83\n",
      "Тренировочный лосс: 1.520885894719292  точность:0.5366701483726501\n",
      "Тестовый лосс: 0.45243552327156067  точность:0.8825063705444336\n",
      "Эпоха 84\n",
      "Тренировочный лосс: 1.5185399725857902  точность:0.537688136100769\n",
      "Тестовый лосс: 0.42209669947624207  точность:0.8848081827163696\n",
      "Эпоха 85\n",
      "Тренировочный лосс: 1.519195376844967  точность:0.5377919673919678\n",
      "Тестовый лосс: 0.4701719284057617  точность:0.8799936175346375\n",
      "Эпоха 86\n",
      "Тренировочный лосс: 1.5155612485549028  точность:0.5377830862998962\n",
      "Тестовый лосс: 0.7037532329559326  точность:0.8651918172836304\n",
      "Эпоха 87\n",
      "Тренировочный лосс: 1.5160774503034704  точность:0.5374318957328796\n",
      "Тестовый лосс: 0.575391948223114  точность:0.8692582845687866\n",
      "Эпоха 88\n",
      "Тренировочный лосс: 1.5128996234781602  точность:0.5383287668228149\n",
      "Тестовый лосс: 0.7494951486587524  точность:0.8596355319023132\n",
      "Эпоха 89\n",
      "Тренировочный лосс: 1.5125738713320565  точность:0.5389931201934814\n",
      "Тестовый лосс: 0.851555585861206  точность:0.8504347801208496\n",
      "Эпоха 90\n",
      "Тренировочный лосс: 1.5114056082332836  точность:0.5389267206192017\n",
      "Тестовый лосс: 5.698993682861328  точность:0.508024275302887\n",
      "Эпоха 91\n",
      "Тренировочный лосс: 1.5131124535728904  точность:0.5385806560516357\n",
      "Тестовый лосс: 4.785714626312256  точность:0.5200127959251404\n",
      "Эпоха 92\n",
      "Тренировочный лосс: 1.5122117746577544  точность:0.5384071469306946\n",
      "Тестовый лосс: 0.4220753610134125  точность:0.8828452825546265\n",
      "Эпоха 93\n",
      "Тренировочный лосс: 1.5100380524467019  точность:0.5400481820106506\n",
      "Тестовый лосс: 1.0874276161193848  точность:0.8395780324935913\n",
      "Эпоха 94\n",
      "Тренировочный лосс: 1.507162050078897  точность:0.5403375029563904\n",
      "Тестовый лосс: 6.991513729095459  точность:0.4461572766304016\n",
      "Эпоха 95\n",
      "Тренировочный лосс: 1.5098733994540046  точность:0.5404126644134521\n",
      "Тестовый лосс: 5.530303001403809  точность:0.5270268321037292\n",
      "Эпоха 96\n",
      "Тренировочный лосс: 1.5084795413297765  точность:0.5405885577201843\n",
      "Тестовый лосс: 0.42665085196495056  точность:0.8864449858665466\n",
      "Эпоха 97\n",
      "Тренировочный лосс: 1.5042773723602294  точность:0.5410106182098389\n",
      "Тестовый лосс: 0.3937413692474365  точность:0.8866751790046692\n"
     ]
    }
   ],
   "source": [
    "#на этой модели я не заметил разницы с нормой градиентов\n",
    "model = ReqModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "cross_entropy = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "ax = fig.subplots(2,1)\n",
    "fig.tight_layout(pad=3.0)\n",
    "ax1, ax2 = ax\n",
    "\n",
    "epochs = 101\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "test_loss_simple = []\n",
    "test_acc_simple = []\n",
    "sampler = CharSampler(char_vectors, model, 'simple.txt')\n",
    "for e in range(epochs):\n",
    "    train_loss_epoch = 0\n",
    "    train_acc_epoch = 0\n",
    "    generator = generate_batch()\n",
    "    for i in range(int(len(sentences) / batch_size)):\n",
    "        X, y = next(generator)\n",
    "        X = torch.from_numpy(X).to(device).float()\n",
    "        y = torch.from_numpy(y).to(device).long()\n",
    "        logits = model(X)\n",
    "        loss = cross_entropy(logits, y.reshape(-1))\n",
    "        train_loss_epoch += loss.item()\n",
    "        train_acc_epoch += torch.mean((y.reshape(-1) == torch.argmax(logits, -1)).float())\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    train_loss_epoch /= int(len(sentences) / batch_size)\n",
    "    train_acc_epoch /= int(len(sentences) / batch_size)\n",
    "    train_loss.append(train_loss_epoch)\n",
    "    train_acc.append(train_acc_epoch)\n",
    "    print(f'Эпоха {e}')\n",
    "    print(f'Тренировочный лосс: {train_loss[-1]}  точность:{train_acc[-1]}')\n",
    "    with torch.no_grad():\n",
    "        logits_test = model(X_test)\n",
    "        loss = cross_entropy(logits_test, y_test.reshape(-1))\n",
    "        test_loss_simple.append(loss.item())\n",
    "        test_acc_simple.append(torch.mean((y_test.reshape(-1) == torch.argmax(logits_test, -1)).float()))\n",
    "    print(f'Тестовый лосс: {test_loss_simple[-1]}  точность:{test_acc_simple[-1]}')\n",
    "    loss_plot(fig,ax1,train_loss, test_loss_simple, \"Кросс-энтропия\")\n",
    "    loss_plot(fig,ax2,train_acc, test_acc_simple, \"Точность\")\n",
    "    sampler.on_epoch_end(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM3Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm1 = nn.LSTM(num_chars, 128, batch_first = True)\n",
    "        self.lstm2 = nn.LSTM(num_chars + 128, 128, batch_first = True)\n",
    "        self.lstm3 = nn.LSTM(num_chars + 128, 128, batch_first = True)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        self.dense = nn.Linear(128 * 3, num_chars)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out1, _ = self.lstm1(X)\n",
    "        out1 = self.tanh(out1)\n",
    "        out1 = self.drop(out1)\n",
    "        out2, _ = self.lstm2(torch.cat([X, out1], 2))\n",
    "        out2 = self.tanh(out2)\n",
    "        out2 = self.drop(out2)\n",
    "        out3, _ = self.lstm3(torch.cat([X, out2], 2))\n",
    "        out3 = self.tanh(out3)\n",
    "        out3 = self.drop(out3)\n",
    "        out = torch.cat([out1, out2, out3], 2)\n",
    "        out = torch.reshape(out, (-1, 128 * 3))\n",
    "        out = self.dense(out)\n",
    "        #X = self.softmax(X)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: notebook. Using widget instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3263f08636c4795a77dfb49007c4768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 0\n",
      "Тренировочный лосс: 2.839977298624375  точность:0.21576911211013794\n",
      "Тестовый лосс: 4.111471176147461  точность:0.0532161109149456\n",
      "Started sampling\n",
      "\tsampling, T =  0.3\n",
      "\tsampling, T =  0.5\n",
      "\tsampling, T =  0.7\n",
      "\tsampling, T =  0.9\n",
      "\tsampling, T =  1.1\n",
      "Эпоха 1\n",
      "Тренировочный лосс: 2.3581260193095486  точность:0.30353787541389465\n",
      "Тестовый лосс: 0.7555564641952515  точность:0.8599552512168884\n",
      "Эпоха 2\n",
      "Тренировочный лосс: 2.1878455669739667  точность:0.34920865297317505\n",
      "Тестовый лосс: 0.45273202657699585  точность:0.868548572063446\n",
      "Эпоха 3\n",
      "Тренировочный лосс: 2.0634936921736773  точность:0.3832738399505615\n",
      "Тестовый лосс: 0.4283387064933777  точность:0.8742391467094421\n",
      "Эпоха 4\n",
      "Тренировочный лосс: 1.9675043798895444  точность:0.4104003608226776\n",
      "Тестовый лосс: 0.4097271263599396  точность:0.8789705634117126\n",
      "Эпоха 5\n",
      "Тренировочный лосс: 1.8886413013233858  точность:0.4326542615890503\n",
      "Тестовый лосс: 0.3930443227291107  точность:0.8826982378959656\n",
      "Эпоха 6\n",
      "Тренировочный лосс: 1.8243494255402508  точность:0.44943422079086304\n",
      "Тестовый лосс: 0.3827362656593323  точность:0.885191798210144\n",
      "Эпоха 7\n",
      "Тренировочный лосс: 1.771989704019883  точность:0.4633615016937256\n",
      "Тестовый лосс: 0.3767769932746887  точность:0.8876150846481323\n",
      "Эпоха 8\n",
      "Тренировочный лосс: 1.7287156315410839  точность:0.4745822548866272\n",
      "Тестовый лосс: 0.36920085549354553  точность:0.8891879916191101\n",
      "Эпоха 9\n",
      "Тренировочный лосс: 1.6903733447018792  точность:0.48478859663009644\n",
      "Тестовый лосс: 0.36349761486053467  точность:0.8901470303535461\n",
      "Эпоха 10\n",
      "Тренировочный лосс: 1.6580930165683523  точность:0.49378103017807007\n",
      "Тестовый лосс: 0.6240929961204529  точность:0.8831138014793396\n",
      "Эпоха 11\n",
      "Тренировочный лосс: 1.6295620772417854  точность:0.501691997051239\n",
      "Тестовый лосс: 0.38960251212120056  точность:0.891508936882019\n",
      "Эпоха 12\n",
      "Тренировочный лосс: 1.6041618826810051  точность:0.5083803534507751\n",
      "Тестовый лосс: 0.38529154658317566  точность:0.8923337459564209\n",
      "Эпоха 13\n",
      "Тренировочный лосс: 1.5803031741871554  точность:0.515307605266571\n",
      "Тестовый лосс: 0.36238715052604675  точность:0.8923913240432739\n",
      "Эпоха 14\n",
      "Тренировочный лосс: 1.5612490034103395  точность:0.5210357904434204\n",
      "Тестовый лосс: 0.42174407839775085  точность:0.8881521821022034\n",
      "Эпоха 15\n",
      "Тренировочный лосс: 1.5438970046884872  точность:0.5250796675682068\n",
      "Тестовый лосс: 1.8858195543289185  точность:0.47938618063926697\n",
      "Эпоха 16\n",
      "Тренировочный лосс: 1.5267629696341123  точность:0.5304411053657532\n",
      "Тестовый лосс: 1.6555112600326538  точность:0.5546355247497559\n",
      "Эпоха 17\n",
      "Тренировочный лосс: 1.5114805698394775  точность:0.5347875356674194\n",
      "Тестовый лосс: 1.4592632055282593  точность:0.713861882686615\n",
      "Эпоха 18\n",
      "Тренировочный лосс: 1.4956421925039853  точность:0.537956953048706\n",
      "Тестовый лосс: 2.76128888130188  точность:0.5191368460655212\n",
      "Эпоха 19\n",
      "Тренировочный лосс: 1.4829501154843499  точность:0.5421897768974304\n",
      "Тестовый лосс: 2.5466179847717285  точность:0.5656585693359375\n",
      "Эпоха 20\n",
      "Тренировочный лосс: 1.4717729624579934  точность:0.5453577041625977\n",
      "Тестовый лосс: 1.9582154750823975  точность:0.6323210000991821\n",
      "Started sampling\n",
      "\tsampling, T =  0.3\n",
      "\tsampling, T =  0.5\n",
      "\tsampling, T =  0.7\n",
      "\tsampling, T =  0.9\n",
      "\tsampling, T =  1.1\n",
      "Эпоха 21\n",
      "Тренировочный лосс: 1.459234567530015  точность:0.5488928556442261\n",
      "Тестовый лосс: 0.777367115020752  точность:0.8278388977050781\n",
      "Эпоха 22\n",
      "Тренировочный лосс: 1.4474237380308264  точность:0.5522912740707397\n",
      "Тестовый лосс: 1.2386858463287354  точность:0.7427173852920532\n",
      "Эпоха 23\n",
      "Тренировочный лосс: 1.440219307787278  точность:0.5541003346443176\n",
      "Тестовый лосс: 0.3496803939342499  точность:0.895108699798584\n",
      "Эпоха 24\n",
      "Тренировочный лосс: 1.4293099448260138  точность:0.5574762225151062\n",
      "Тестовый лосс: 0.3520396649837494  точность:0.8947186470031738\n",
      "Эпоха 25\n",
      "Тренировочный лосс: 1.4181232557577246  точность:0.5607596039772034\n",
      "Тестовый лосс: 0.43780237436294556  точность:0.8798593282699585\n",
      "Эпоха 26\n",
      "Тренировочный лосс: 1.4100188823307263  точность:0.5629795789718628\n",
      "Тестовый лосс: 1.4642857313156128  точность:0.6964002847671509\n",
      "Эпоха 27\n",
      "Тренировочный лосс: 1.400754326091093  точность:0.5656602382659912\n",
      "Тестовый лосс: 1.9828262329101562  точность:0.6382736563682556\n",
      "Эпоха 28\n",
      "Тренировочный лосс: 1.3942885832225576  точность:0.5666710734367371\n",
      "Тестовый лосс: 2.0147604942321777  точность:0.6457992196083069\n",
      "Эпоха 29\n",
      "Тренировочный лосс: 1.3857588567453272  точность:0.5701375007629395\n",
      "Тестовый лосс: 2.6799769401550293  точность:0.56991046667099\n",
      "Эпоха 30\n",
      "Тренировочный лосс: 1.3787581118415384  точность:0.5721265077590942\n",
      "Тестовый лосс: 1.579854965209961  точность:0.6734015345573425\n",
      "Эпоха 31\n",
      "Тренировочный лосс: 1.3709252044733833  точность:0.5742129683494568\n",
      "Тестовый лосс: 1.5163816213607788  точность:0.6991176605224609\n",
      "Эпоха 32\n",
      "Тренировочный лосс: 1.3640936371859382  точность:0.5757677555084229\n",
      "Тестовый лосс: 2.9037561416625977  точность:0.5263426899909973\n",
      "Эпоха 33\n",
      "Тренировочный лосс: 1.3572680208262276  точность:0.5781665444374084\n",
      "Тестовый лосс: 2.275174617767334  точность:0.6260997653007507\n",
      "Эпоха 34\n",
      "Тренировочный лосс: 1.3523835738967447  точность:0.579196572303772\n",
      "Тестовый лосс: 1.2538079023361206  точность:0.6900703310966492\n",
      "Эпоха 35\n",
      "Тренировочный лосс: 1.3451411031274234  точность:0.5817261338233948\n",
      "Тестовый лосс: 2.289555311203003  точность:0.5637660026550293\n",
      "Эпоха 36\n",
      "Тренировочный лосс: 1.3381598242591408  точность:0.5837187170982361\n",
      "Тестовый лосс: 2.585965394973755  точность:0.5916751623153687\n",
      "Эпоха 37\n",
      "Тренировочный лосс: 1.3331403394306407  точность:0.5849378108978271\n",
      "Тестовый лосс: 1.7610266208648682  точность:0.6194948554039001\n",
      "Эпоха 38\n",
      "Тренировочный лосс: 1.3271254216923434  точность:0.586334228515625\n",
      "Тестовый лосс: 1.3009954690933228  точность:0.7199872136116028\n",
      "Эпоха 39\n",
      "Тренировочный лосс: 1.3222333103067734  точность:0.5885491967201233\n",
      "Тестовый лосс: 2.067441940307617  точность:0.6138107180595398\n",
      "Эпоха 40\n",
      "Тренировочный лосс: 1.3179911260043873  точность:0.5886988639831543\n",
      "Тестовый лосс: 0.35165372490882874  точность:0.8966816067695618\n",
      "Started sampling\n",
      "\tsampling, T =  0.3\n",
      "\tsampling, T =  0.5\n",
      "\tsampling, T =  0.7\n",
      "\tsampling, T =  0.9\n",
      "\tsampling, T =  1.1\n",
      "Эпоха 41\n",
      "Тренировочный лосс: 1.3126205033414504  точность:0.5909978151321411\n",
      "Тестовый лосс: 0.344615638256073  точность:0.8978388905525208\n",
      "Эпоха 42\n",
      "Тренировочный лосс: 1.3051375115618986  точность:0.5936664342880249\n",
      "Тестовый лосс: 0.348058819770813  точность:0.8974488377571106\n",
      "Эпоха 43\n",
      "Тренировочный лосс: 1.3017112768397612  точность:0.5941213965415955\n",
      "Тестовый лосс: 0.34518498182296753  точность:0.8987275958061218\n",
      "Эпоха 44\n",
      "Тренировочный лосс: 1.296737071906819  точность:0.5957738757133484\n",
      "Тестовый лосс: 0.34668779373168945  точность:0.8982161283493042\n",
      "Эпоха 45\n",
      "Тренировочный лосс: 1.2940056884990019  точность:0.5961301326751709\n",
      "Тестовый лосс: 0.3455766439437866  точность:0.8980434536933899\n",
      "Эпоха 46\n",
      "Тренировочный лосс: 1.2878447883269366  точность:0.5986874103546143\n",
      "Тестовый лосс: 0.3483816087245941  точность:0.8978133201599121\n",
      "Эпоха 47\n",
      "Тренировочный лосс: 1.2846489366363076  точность:0.5994038581848145\n",
      "Тестовый лосс: 0.3455227017402649  точность:0.8985422253608704\n",
      "Эпоха 48\n",
      "Тренировочный лосс: 1.2804600122395684  точность:0.6006787419319153\n",
      "Тестовый лосс: 0.3487398624420166  точность:0.8976023197174072\n",
      "Эпоха 49\n",
      "Тренировочный лосс: 1.2755599671251634  точность:0.6025328636169434\n",
      "Тестовый лосс: 0.34617000818252563  точность:0.8982096910476685\n",
      "Эпоха 50\n",
      "Тренировочный лосс: 1.2727772182576798  точность:0.6023485660552979\n",
      "Тестовый лосс: 0.34826409816741943  точность:0.8979156017303467\n",
      "Эпоха 51\n",
      "Тренировочный лосс: 1.2697204606673296  точность:0.6030596494674683\n",
      "Тестовый лосс: 0.34664595127105713  точность:0.8977493643760681\n",
      "Эпоха 52\n",
      "Тренировочный лосс: 1.2645318917667165  точность:0.6043553948402405\n",
      "Тестовый лосс: 0.34558627009391785  точность:0.898510217666626\n",
      "Эпоха 53\n",
      "Тренировочный лосс: 1.2619535917394302  точность:0.60614013671875\n",
      "Тестовый лосс: 0.34702184796333313  точность:0.8986316919326782\n",
      "Эпоха 54\n",
      "Тренировочный лосс: 1.2594767165184022  точность:0.606546938419342\n",
      "Тестовый лосс: 0.3474227786064148  точность:0.8985422253608704\n",
      "Эпоха 55\n",
      "Тренировочный лосс: 1.2532775144016042  точность:0.6079438328742981\n",
      "Тестовый лосс: 0.3449976444244385  точность:0.8988810777664185\n",
      "Эпоха 56\n",
      "Тренировочный лосс: 1.2527300785569584  точность:0.6089134812355042\n",
      "Тестовый лосс: 0.3469003736972809  точность:0.8978772163391113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 57\n",
      "Тренировочный лосс: 1.2488006006970125  точность:0.6103459596633911\n",
      "Тестовый лосс: 0.3497077524662018  точность:0.8987787961959839\n",
      "Эпоха 58\n",
      "Тренировочный лосс: 1.2457782333037433  точность:0.6108003258705139\n",
      "Тестовый лосс: 0.34723082184791565  точность:0.8984654545783997\n",
      "Эпоха 59\n",
      "Тренировочный лосс: 1.2424870607432197  точность:0.6118929982185364\n",
      "Тестовый лосс: 0.3492526412010193  точность:0.8979284167289734\n",
      "Эпоха 60\n",
      "Тренировочный лосс: 1.2382978489819696  точность:0.6138525605201721\n",
      "Тестовый лосс: 0.3470187485218048  точность:0.8983056545257568\n",
      "Started sampling\n",
      "\tsampling, T =  0.3\n",
      "\tsampling, T =  0.5\n",
      "\tsampling, T =  0.7\n",
      "\tsampling, T =  0.9\n",
      "\tsampling, T =  1.1\n",
      "Эпоха 61\n",
      "Тренировочный лосс: 1.2352123776604147  точность:0.6141741275787354\n",
      "Тестовый лосс: 0.3472181260585785  точность:0.8985486030578613\n",
      "Эпоха 62\n",
      "Тренировочный лосс: 1.2332307192858527  точность:0.6139135360717773\n",
      "Тестовый лосс: 0.34649237990379333  точность:0.898638129234314\n",
      "Эпоха 63\n",
      "Тренировочный лосс: 1.230240220602821  точность:0.615841269493103\n",
      "Тестовый лосс: 0.34502267837524414  точность:0.8992135524749756\n",
      "Эпоха 64\n",
      "Тренировочный лосс: 1.227760268239414  точность:0.6161779761314392\n",
      "Тестовый лосс: 0.34775176644325256  точность:0.8981713652610779\n",
      "Эпоха 65\n",
      "Тренировочный лосс: 1.2242974235029782  точность:0.6180533170700073\n",
      "Тестовый лосс: 0.34734201431274414  точность:0.8988555073738098\n",
      "Эпоха 66\n",
      "Тренировочный лосс: 1.2221790901352378  точность:0.6177393198013306\n",
      "Тестовый лосс: 0.35266464948654175  точность:0.8979987502098083\n",
      "Эпоха 67\n",
      "Тренировочный лосс: 1.2207923800805036  точность:0.6188539266586304\n",
      "Тестовый лосс: 0.3526438772678375  точность:0.8975191712379456\n",
      "Эпоха 68\n",
      "Тренировочный лосс: 1.217317403344547  точность:0.6193636059761047\n",
      "Тестовый лосс: 0.3479536473751068  точность:0.8987723588943481\n",
      "Эпоха 69\n",
      "Тренировочный лосс: 1.2151774280211505  точность:0.6206452250480652\n",
      "Тестовый лосс: 0.3477979898452759  точность:0.8982096910476685\n",
      "Эпоха 70\n",
      "Тренировочный лосс: 1.2118019080162048  точность:0.6209337711334229\n",
      "Тестовый лосс: 0.35304972529411316  точность:0.8969820737838745\n",
      "Эпоха 71\n",
      "Тренировочный лосс: 1.210292358117945  точность:0.6220461130142212\n",
      "Тестовый лосс: 0.3473597466945648  точность:0.8987659811973572\n",
      "Эпоха 72\n",
      "Тренировочный лосс: 1.2080393101187312  точность:0.6222786903381348\n",
      "Тестовый лосс: 0.3506592810153961  точность:0.8975447416305542\n",
      "Эпоха 73\n",
      "Тренировочный лосс: 1.206006085171419  точность:0.6223747730255127\n",
      "Тестовый лосс: 0.3500642776489258  точность:0.8979219794273376\n",
      "Эпоха 74\n",
      "Тренировочный лосс: 1.2050649060922511  точность:0.6233772039413452\n",
      "Тестовый лосс: 0.3527775704860687  точность:0.8977301716804504\n",
      "Эпоха 75\n",
      "Тренировочный лосс: 1.1998701837483574  точность:0.6255859136581421\n",
      "Тестовый лосс: 0.35045570135116577  точность:0.8982416987419128\n",
      "Эпоха 76\n",
      "Тренировочный лосс: 1.1970113246581133  точность:0.6252038478851318\n",
      "Тестовый лосс: 0.34574028849601746  точность:0.8988426923751831\n",
      "Эпоха 77\n",
      "Тренировочный лосс: 1.1968267651165232  точность:0.6261444687843323\n",
      "Тестовый лосс: 0.3487769663333893  точность:0.898439884185791\n",
      "Эпоха 78\n",
      "Тренировочный лосс: 1.1940727424621582  точность:0.6259593963623047\n",
      "Тестовый лосс: 0.3524472117424011  точность:0.8976215124130249\n",
      "Эпоха 79\n",
      "Тренировочный лосс: 1.1908692653038921  точность:0.6267154216766357\n",
      "Тестовый лосс: 0.3502964973449707  точность:0.8976790308952332\n",
      "Эпоха 80\n",
      "Тренировочный лосс: 1.1897918110735277  точность:0.6276102066040039\n",
      "Тестовый лосс: 0.35379698872566223  точность:0.8978772163391113\n",
      "Started sampling\n",
      "\tsampling, T =  0.3\n",
      "\tsampling, T =  0.5\n",
      "\tsampling, T =  0.7\n",
      "\tsampling, T =  0.9\n",
      "\tsampling, T =  1.1\n",
      "Эпоха 81\n",
      "Тренировочный лосс: 1.189444915266598  точность:0.6281901001930237\n",
      "Тестовый лосс: 0.3510141372680664  точность:0.8981649875640869\n",
      "Эпоха 82\n",
      "Тренировочный лосс: 1.1858593400786905  точность:0.6292933821678162\n",
      "Тестовый лосс: 0.35598987340927124  точность:0.8972314596176147\n",
      "Эпоха 83\n",
      "Тренировочный лосс: 1.185317944498623  точность:0.6287526488304138\n",
      "Тестовый лосс: 0.3498854339122772  точность:0.8985933661460876\n",
      "Эпоха 84\n",
      "Тренировочный лосс: 1.1815325607972986  точность:0.6301930546760559\n",
      "Тестовый лосс: 0.3528866767883301  точность:0.8981137871742249\n",
      "Эпоха 85\n",
      "Тренировочный лосс: 1.1809175534809337  точность:0.6304091811180115\n",
      "Тестовый лосс: 0.35392022132873535  точность:0.8981969356536865\n",
      "Эпоха 86\n",
      "Тренировочный лосс: 1.1795693398924434  точность:0.6312451362609863\n",
      "Тестовый лосс: 0.3996982276439667  точность:0.8895652294158936\n",
      "Эпоха 87\n",
      "Тренировочный лосс: 1.176220952202292  точность:0.6316038370132446\n",
      "Тестовый лосс: 0.35692232847213745  точность:0.8970396518707275\n",
      "Эпоха 88\n",
      "Тренировочный лосс: 1.1753586965448717  точность:0.6318912506103516\n",
      "Тестовый лосс: 0.347188264131546  точность:0.8990665078163147\n",
      "Эпоха 89\n",
      "Тренировочный лосс: 1.1733273356101093  точность:0.6326400637626648\n",
      "Тестовый лосс: 0.3596045672893524  точность:0.896732747554779\n",
      "Эпоха 90\n",
      "Тренировочный лосс: 1.172036459305707  точность:0.6329458951950073\n",
      "Тестовый лосс: 0.35323598980903625  точность:0.8981457948684692\n",
      "Эпоха 91\n",
      "Тренировочный лосс: 1.1693312379893135  точность:0.6339530348777771\n",
      "Тестовый лосс: 0.34952685236930847  точность:0.8986892700195312\n",
      "Эпоха 92\n",
      "Тренировочный лосс: 1.169465821911307  точность:0.6343275308609009\n",
      "Тестовый лосс: 0.3498212695121765  точность:0.898503839969635\n",
      "Эпоха 93\n",
      "Тренировочный лосс: 1.16784638040206  точность:0.6347151398658752\n",
      "Тестовый лосс: 0.35053709149360657  точность:0.898497462272644\n",
      "Эпоха 94\n",
      "Тренировочный лосс: 1.1654831856839798  точность:0.6344558000564575\n",
      "Тестовый лосс: 0.3493288457393646  точность:0.8985422253608704\n",
      "Эпоха 95\n",
      "Тренировочный лосс: 1.1636378819802229  точность:0.6361187696456909\n",
      "Тестовый лосс: 0.3529317080974579  точность:0.8982288837432861\n",
      "Эпоха 96\n",
      "Тренировочный лосс: 1.162222356375526  точность:0.6360185146331787\n",
      "Тестовый лосс: 0.34914669394493103  точность:0.8988682627677917\n",
      "Эпоха 97\n",
      "Тренировочный лосс: 1.1601349611843335  точность:0.6366183161735535\n",
      "Тестовый лосс: 0.35181528329849243  точность:0.8985294103622437\n",
      "Эпоха 98\n",
      "Тренировочный лосс: 1.1589542935876285  точность:0.6370851993560791\n",
      "Тестовый лосс: 0.35116714239120483  точность:0.8985294103622437\n",
      "Эпоха 99\n",
      "Тренировочный лосс: 1.1595283807025236  точность:0.6370819211006165\n",
      "Тестовый лосс: 0.34834232926368713  точность:0.8989961743354797\n",
      "Эпоха 100\n",
      "Тренировочный лосс: 1.1568772844707265  точность:0.6379960179328918\n",
      "Тестовый лосс: 0.3507849872112274  точность:0.8985805511474609\n",
      "Started sampling\n",
      "\tsampling, T =  0.3\n",
      "\tsampling, T =  0.5\n",
      "\tsampling, T =  0.7\n",
      "\tsampling, T =  0.9\n",
      "\tsampling, T =  1.1\n"
     ]
    }
   ],
   "source": [
    "#на этой модели я не заметил разницы с нормой градиентов\n",
    "model = LSTM3Model().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "cross_entropy = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "ax = fig.subplots(2,1)\n",
    "fig.tight_layout(pad=3.0)\n",
    "ax1, ax2 = ax\n",
    "\n",
    "epochs = 101\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "sampler = CharSampler(char_vectors, model, 'stacked_with_skip.txt')\n",
    "for e in range(epochs):\n",
    "    train_loss_epoch = 0\n",
    "    train_acc_epoch = 0\n",
    "    generator = generate_batch()\n",
    "    for i in range(int(len(sentences) / batch_size)):\n",
    "        X, y = next(generator)\n",
    "        X = torch.from_numpy(X).to(device).float()\n",
    "        y = torch.from_numpy(y).to(device).long()\n",
    "        logits = model(X)\n",
    "        loss = cross_entropy(logits, y.reshape(-1))\n",
    "        train_loss_epoch += loss.item()\n",
    "        train_acc_epoch += torch.mean((y.reshape(-1) == torch.argmax(logits, -1)).float())\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    train_loss_epoch /= int(len(sentences) / batch_size)\n",
    "    train_acc_epoch /= int(len(sentences) / batch_size)\n",
    "    train_loss.append(train_loss_epoch)\n",
    "    train_acc.append(train_acc_epoch)\n",
    "    print(f'Эпоха {e}')\n",
    "    print(f'Тренировочный лосс: {train_loss[-1]}  точность:{train_acc[-1]}')\n",
    "    with torch.no_grad():\n",
    "        logits_test = model(X_test)\n",
    "        loss = cross_entropy(logits_test, y_test.reshape(-1))\n",
    "        test_loss.append(loss.item())\n",
    "        test_acc.append(torch.mean((y_test.reshape(-1) == torch.argmax(logits_test, -1)).float()))\n",
    "    print(f'Тестовый лосс: {test_loss[-1]}  точность:{test_acc[-1]}')\n",
    "    loss_plot(fig,ax1,train_loss, test_loss, \"Кросс-энтропия\")\n",
    "    loss_plot(fig,ax2,train_acc, test_acc, \"Точность\")\n",
    "    sampler.on_epoch_end(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize=(8,10))\n",
    "ax1 = fig.plot()\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "train_line = ax1.plot(test_acc_simple, color = 'black')\n",
    "test_line = ax1.plot(test_acc, color = 'red')\n",
    "ax1.set_xlabel('Эпоха')\n",
    "ax1.set_ylabel('Точность')\n",
    "ax1.legend(('1 слой', '3слоя'))\n",
    "fig.canvas.draw()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
